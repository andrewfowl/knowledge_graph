{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run in terminal:\n",
    "pip install typing-extensions<4.6.0\n",
    "pip install pillow<10.1.0,>=8.3.2\n",
    "pip install fastapi kaleido uvicorn\n",
    "pip install langchain\n",
    "pip install pypdf\n",
    "pip install unstructured\n",
    "pip install yachalk\n",
    "pip install \"unstructured[pdf]\"\n",
    "pip install openai\n",
    "sudo apt update\n",
    "sudo apt-get install libgl1-mesa-glx\n",
    "pip install --upgrade jupyter ipywidgets\n",
    "pip install --upgrade opencv-python-headless\n",
    "export OPENAI_API_KEY=\"...\"\n",
    "pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import uuid\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "\n",
    "## Input data directory\n",
    "data_dir = \"coin\"\n",
    "inputdirectory = Path(f\"./data_input/{data_dir}\")\n",
    "## This is where the output csv files will be written\n",
    "out_dir = data_dir\n",
    "outputdirectory = Path(f\"./data_output/{out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_id = os.getenv(\"OPENAI_ORG_ID\") \n",
    "client = OpenAI(organization=org_id)\n",
    "\n",
    "def graphPrompt(input: str, metadata={}, model=\"gpt-4-0125-preview\"):\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "\n",
    "\n",
    "    # model_info = client.show(model_name=model)\n",
    "    # print( chalk.blue(model_info))\n",
    "\n",
    "    SYS_PROMPT = (\n",
    "        \"You are a network graph maker who extracts terms and their relations from a given context. \"\n",
    "        \"You are provided with a context chunk (delimited by ```) Your task is to extract the ontology \"\n",
    "        \"of terms mentioned in the given context. These terms should represent the key concepts as per the context. \\n\"\n",
    "        \"Thought 1: While traversing through each sentence, Think about the key terms mentioned in it.\\n\"\n",
    "            \"\\tTerms may include object, entity, location, organization, person, \\n\"\n",
    "            \"\\tcondition, acronym, documents, service, concept, etc.\\n\"\n",
    "            \"\\tTerms should be as atomistic as possible\\n\\n\"\n",
    "        \"Thought 2: Think about how these terms can have one on one relation with other terms.\\n\"\n",
    "            \"\\tTerms that are mentioned in the same sentence or the same paragraph are typically related to each other.\\n\"\n",
    "            \"\\tTerms can be related to many other terms\\n\\n\"\n",
    "        \"Thought 3: Find out the relation between each such related pair of terms. \\n\\n\"\n",
    "        \"Format your output as a list of json. Each element of the list contains a pair of terms\"\n",
    "        \"and the relation between them, like the follwing: \\n\"\n",
    "        \"[\\n\"\n",
    "        \"   {\\n\"\n",
    "        '       \"node_1\": \"A concept from extracted ontology\",\\n'\n",
    "        '       \"node_2\": \"A related concept from extracted ontology\",\\n'\n",
    "        '       \"edge\": \"relationship between the two concepts, node_1 and node_2 in one or two sentences\"\\n'\n",
    "        \"   }, {...}\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "\n",
    "    USER_PROMPT = f\"context: ```{input}``` \\n\\n output: \"\n",
    "   # response, _ = client.generate(model_name=model, system=SYS_PROMPT, prompt=USER_PROMPT)\n",
    "            \n",
    "    response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "    ],\n",
    "    max_tokens=500,\n",
    "    stop=\"\\t  \\t  \\t\"\n",
    "    )\n",
    "    try:\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "        #print('content', content)\n",
    "        \n",
    "        # Parse the JSON string\n",
    "        parsed_content = json.loads(content)\n",
    "\n",
    "        # Handle single object or list\n",
    "        if isinstance(parsed_content, dict):\n",
    "            result = [dict(parsed_content, **metadata)]\n",
    "        elif isinstance(parsed_content, list):\n",
    "            result = [dict(item, **metadata) for item in parsed_content]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected data format in response\")\n",
    "\n",
    "        #print('result', result)\n",
    "    except Exception as e:\n",
    "        print(\"\\n\\nERROR ### Here is the errored response: \", response, \"\\n\\nException: \", e)\n",
    "        result = None\n",
    "    print('graph prompt function success')\n",
    "    time.sleep(1)\n",
    "    return result\n",
    "\n",
    "def df2Graph(dataframe: pd.DataFrame, model=None) -> list:\n",
    "    # dataframe.reset_index(inplace=True)\n",
    "    results = dataframe.apply(\n",
    "        lambda row: graphPrompt(row.text, {\"chunk_id\": row.chunk_id}, model), axis=1\n",
    "    )\n",
    "    # invalid json results in NaN\n",
    "    results = results.dropna()\n",
    "    results = results.reset_index(drop=True)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities.\n",
    "    concept_list = np.concatenate(results).ravel().tolist()\n",
    "    return concept_list\n",
    "\n",
    "\n",
    "def graph2Df(nodes_list) -> pd.DataFrame:\n",
    "    ## Remove all NaN entities\n",
    "    graph_dataframe = pd.DataFrame(nodes_list).replace(\" \", np.nan)\n",
    "    graph_dataframe = graph_dataframe.dropna(subset=[\"node_1\", \"node_2\"])\n",
    "    graph_dataframe[\"node_1\"] = graph_dataframe[\"node_1\"].apply(lambda x: x.lower())\n",
    "    graph_dataframe[\"node_2\"] = graph_dataframe[\"node_2\"].apply(lambda x: x.lower())\n",
    "\n",
    "    return graph_dataframe\n",
    "\n",
    "def append_df_to_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    Append a DataFrame to a CSV file. If the file does not exist, create it with a header.\n",
    "    If the file exists, append without a header.\n",
    "\n",
    "    :param df: DataFrame to be appended\n",
    "    :param file_path: Path to the CSV file\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    time.sleep(1)\n",
    "    # If file exists, append without header; otherwise, write with header\n",
    "    if file_exists:\n",
    "        df.to_csv(file_path, sep=\"|\", mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(file_path, sep=\"|\", mode='w', header=True, index=False)\n",
    "\n",
    "def documents2Dataframe(documents) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for chunk in documents:\n",
    "        row = {\n",
    "            \"text\": chunk.page_content,\n",
    "            **chunk.metadata,\n",
    "            \"chunk_id\": uuid.uuid4().hex,\n",
    "        }\n",
    "        rows = rows + [row]\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHEN RECREATING BASED ON NEW PDF RUN THIS:\n",
    "## Dir PDF Loader\n",
    "loader = PyPDFDirectoryLoader(inputdirectory)\n",
    "## File Loader\n",
    "#loader = PyPDFLoader(\"./data_input/coin/coinbase.pdf\")\n",
    "#loader = DirectoryLoader(inputdirectory, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "pages = splitter.split_documents(documents)\n",
    "df = documents2Dataframe(pages)\n",
    "df.to_csv(\"df.csv\", sep=\"|\", index=False)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>page</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In addition, statements that “we believe” and ...</td>\n",
       "      <td>data_input/coin/coinbase.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>685bcea8f090463682d7b4fef816d0d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n 6\\n•Our net revenue may be concentrated in ...</td>\n",
       "      <td>data_input/coin/coinbase.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>6c11c774004842c3892f9cf89ce6868f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>•Cyberattacks and security breaches of our pla...</td>\n",
       "      <td>data_input/coin/coinbase.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>be628a8b4ebe499baf37b2b128ef1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>•We are, and may continue to be, subject to ma...</td>\n",
       "      <td>data_input/coin/coinbase.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>1888bf80179e4378863ff36950f3eba5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n 7\\n•We currently rely on third-party servic...</td>\n",
       "      <td>data_input/coin/coinbase.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>61c2ee4a35494431b324e8501d75e4dc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  In addition, statements that “we believe” and ...   \n",
       "1  \\n 6\\n•Our net revenue may be concentrated in ...   \n",
       "2  •Cyberattacks and security breaches of our pla...   \n",
       "3  •We are, and may continue to be, subject to ma...   \n",
       "4  \\n 7\\n•We currently rely on third-party servic...   \n",
       "\n",
       "                         source  page                          chunk_id  \n",
       "0  data_input/coin/coinbase.pdf     4  685bcea8f090463682d7b4fef816d0d3  \n",
       "1  data_input/coin/coinbase.pdf     5  6c11c774004842c3892f9cf89ce6868f  \n",
       "2  data_input/coin/coinbase.pdf     5  be628a8b4ebe499baf37b2b128ef1863  \n",
       "3  data_input/coin/coinbase.pdf     5  1888bf80179e4378863ff36950f3eba5  \n",
       "4  data_input/coin/coinbase.pdf     6  61c2ee4a35494431b324e8501d75e4dc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WHEN USING PREPROCESSED PDF SAVED IN CSV RUN THIS\n",
    "df = pd.read_csv('df.csv', sep=\"|\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks total of  226\n",
      "df2Graph started chunk #0/226\n",
      "graph prompt function success\n",
      "\n",
      "\n",
      "ERROR ### Here is the errored response:  ChatCompletion(id='chatcmpl-8nDrkxrC7Vq6ZlWtgp37sqeXBpZIK', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       \\t    \\n   \\t       ', role='assistant', function_call=None, tool_calls=None))], created=1706742064, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_376b7f78b9', usage=CompletionUsage(completion_tokens=500, prompt_tokens=666, total_tokens=1166)) \n",
      "\n",
      "Exception:  Expecting value: line 167 column 12 (char 2833)\n",
      "graph prompt function success\n",
      "df2Graph finished chunk #0/226\n",
      "saved graph and chunk #0 csv files\n",
      "df2Graph started chunk #1/226\n",
      "graph prompt function success\n",
      "graph prompt function success\n",
      "df2Graph finished chunk #1/226\n",
      "saved graph and chunk #1 csv files\n",
      "df2Graph started chunk #2/226\n",
      "\n",
      "\n",
      "ERROR ### Here is the errored response:  ChatCompletion(id='chatcmpl-8nDsahZQZvGhEW5gIlu0tNZg1umeD', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n\\n\\n\\n        \\n\\n\\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n   \\n   \\t    \\n   \\t       \\n   \\t        \\n\\n  \\n', role='assistant', function_call=None, tool_calls=None))], created=1706742116, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_156aa2d12a', usage=CompletionUsage(completion_tokens=500, prompt_tokens=580, total_tokens=1080)) \n",
      "\n",
      "Exception:  Expecting value: line 307 column 1 (char 2101)\n",
      "graph prompt function success\n",
      "graph prompt function success\n",
      "df2Graph finished chunk #2/226\n",
      "saved graph and chunk #2 csv files\n",
      "df2Graph started chunk #3/226\n",
      "graph prompt function success\n",
      "graph prompt function success\n",
      "df2Graph finished chunk #3/226\n",
      "saved graph and chunk #3 csv files\n",
      "df2Graph started chunk #4/226\n",
      "graph prompt function success\n",
      "graph prompt function success\n",
      "df2Graph finished chunk #4/226\n",
      "saved graph and chunk #4 csv files\n",
      "df2Graph started chunk #5/226\n",
      "graph prompt function success\n",
      "\n",
      "\n",
      "ERROR ### Here is the errored response:  ChatCompletion(id='chatcmpl-8nDufTeJgv95EAOoEBTzI4puo7TR6', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n   \\t    \\n', role='assistant', function_call=None, tool_calls=None))], created=1706742245, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_156aa2d12a', usage=CompletionUsage(completion_tokens=500, prompt_tokens=516, total_tokens=1016)) \n",
      "\n",
      "Exception:  Expecting value: line 251 column 1 (char 2250)\n",
      "graph prompt function success\n",
      "df2Graph finished chunk #5/226\n",
      "saved graph and chunk #5 csv files\n",
      "df2Graph started chunk #6/226\n",
      "graph prompt function success\n",
      "graph prompt function success\n",
      "df2Graph finished chunk #6/226\n",
      "saved graph and chunk #6 csv files\n",
      "df2Graph started chunk #7/226\n",
      "graph prompt function success\n",
      "\n",
      "\n",
      "ERROR ### Here is the errored response:  ChatCompletion(id='chatcmpl-8nDvVOCQ4AI62CQ8jmw6I7JlO9EvH', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='\\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       \\n        \\n       ', role='assistant', function_call=None, tool_calls=None))], created=1706742297, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_376b7f78b9', usage=CompletionUsage(completion_tokens=500, prompt_tokens=641, total_tokens=1141)) \n",
      "\n",
      "Exception:  Expecting value: line 500 column 8 (char 4241)\n",
      "graph prompt function success\n",
      "df2Graph finished chunk #7/226\n",
      "saved graph and chunk #7 csv files\n",
      "df2Graph started chunk #8/226\n",
      "graph prompt function success\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dfgcsv(dataframe: pd.DataFrame, model=\"gpt-4-0125-preview\") -> pd.DataFrame:\n",
    "    chunk_size = 2 # Processing in chunks of 20 rows\n",
    "    chunks = [dataframe[i:i + chunk_size] for i in range(0, dataframe.shape[0], chunk_size)]\n",
    "    chunkstotal = len(chunks)\n",
    "    print('chunks total of ', chunkstotal)\n",
    "    chunk_concepts = []\n",
    "    counter=0\n",
    "    for chunk in chunks:\n",
    "        results = pd.DataFrame()\n",
    "        print(f'df2Graph started chunk #{counter}/{chunkstotal}')\n",
    "        #chunk.reset_index(inplace=True)\n",
    "        results = chunk.apply(lambda row: graphPrompt(row.text, {\"chunk_id\": row.chunk_id}, model=\"gpt-4-0125-preview\"), axis=1)\n",
    "        # invalid json results in NaN\n",
    "        results = results.dropna()\n",
    "        results = results.reset_index(drop=True)\n",
    "        ## Flatten the list of lists to one single list of entities.\n",
    "        chunk_concepts = np.concatenate(results).ravel().tolist()\n",
    "        graph_dataframe = pd.DataFrame(chunk_concepts).replace(\" \", np.nan)\n",
    "        graph_dataframe = graph_dataframe.dropna(subset=[\"node_1\", \"node_2\"])\n",
    "        graph_dataframe[\"node_1\"] = graph_dataframe[\"node_1\"].apply(lambda x: x.lower())\n",
    "        graph_dataframe[\"node_2\"] = graph_dataframe[\"node_2\"].apply(lambda x: x.lower())\n",
    "        print(f'df2Graph finished chunk #{counter}/{chunkstotal}')\n",
    "        append_df_to_csv(graph_dataframe, os.path.join(outputdirectory, \"graph.csv\"))\n",
    "        append_df_to_csv(chunk, os.path.join(outputdirectory, \"chunks.csv\"))\n",
    "        print(f'saved graph and chunk #{counter} csv files')\n",
    "        #graph_dataframe.to_csv(os.path.join(outputdirectory, \"graph.csv\"), sep=\"|\", mode='a', header=False, index=False)\n",
    "        #chunk.to_csv(os.path.join(outputdirectory, \"chunks.csv\"), sep=\"|\", mode='a', header=False, index=False)\n",
    "        time.sleep(0.1)\n",
    "        counter=counter+1\n",
    "        chunk_concepts=[]\n",
    "\n",
    "    msg = print(f'Success on {counter} chunks')\n",
    "    return msg\n",
    "\n",
    "dfgcsv(dataframe=df, model=\"gpt-4-0125-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If regenerate is set to True then the dataframes are regenerated and Both the dataframes are written in the csv format so we dont have to calculate them again. \n",
    "\n",
    "        dfne = dataframe of edges\n",
    "\n",
    "        df = dataframe of chunks\n",
    "\n",
    "\n",
    "Else the dataframes are read from the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>edge</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crypto assets</td>\n",
       "      <td>transaction</td>\n",
       "      <td>Crypto assets are relevant at the time of the ...</td>\n",
       "      <td>53bc890b95f44a468fd4092745665c70</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>updated arrangement</td>\n",
       "      <td>counterparty</td>\n",
       "      <td>The updated arrangement is made with the same ...</td>\n",
       "      <td>45ffdb5f262542c9ae95b8d8e071b5b6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coinbase global, inc.</td>\n",
       "      <td>blockchain rewards</td>\n",
       "      <td>Coinbase Global, Inc. records blockchain rewar...</td>\n",
       "      <td>56d7a6832cb748ffaf5cad1b01169bb9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digital wallet</td>\n",
       "      <td>company</td>\n",
       "      <td>is controlled by the Company</td>\n",
       "      <td>6415bc1cdcfa4df88541d06ca2285198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>performance obligation</td>\n",
       "      <td>contracts</td>\n",
       "      <td>One performance obligation is typically provid...</td>\n",
       "      <td>0f7d1c65605a4d57ae4792f63c906205</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   node_1              node_2  \\\n",
       "0           crypto assets         transaction   \n",
       "1     updated arrangement        counterparty   \n",
       "2   coinbase global, inc.  blockchain rewards   \n",
       "3          digital wallet             company   \n",
       "4  performance obligation           contracts   \n",
       "\n",
       "                                                edge  \\\n",
       "0  Crypto assets are relevant at the time of the ...   \n",
       "1  The updated arrangement is made with the same ...   \n",
       "2  Coinbase Global, Inc. records blockchain rewar...   \n",
       "3                       is controlled by the Company   \n",
       "4  One performance obligation is typically provid...   \n",
       "\n",
       "                           chunk_id  count  \n",
       "0  53bc890b95f44a468fd4092745665c70      4  \n",
       "1  45ffdb5f262542c9ae95b8d8e071b5b6      4  \n",
       "2  56d7a6832cb748ffaf5cad1b01169bb9      4  \n",
       "3  6415bc1cdcfa4df88541d06ca2285198      4  \n",
       "4  0f7d1c65605a4d57ae4792f63c906205      4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regenerate = True\n",
    "if regenerate:\n",
    "    dfgcsv(dataframe=df, model=\"gpt-4-0125-preview\")\n",
    "\n",
    "dfg1 = pd.read_csv(os.path.join(outputdirectory, \"graph.csv\"), sep=\"|\")\n",
    "dfg1.replace(\"\", np.nan, inplace=True)\n",
    "dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "dfg1['count'] = 4 \n",
    "## Increasing the weight of the relation to 4. \n",
    "## We will assign the weight of 1 when later the contextual proximity will be calculated.  \n",
    "print(dfg1.shape)\n",
    "dfg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating contextual proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beliefs and opinions</td>\n",
       "      <td>statements</td>\n",
       "      <td>685bcea8f090463682d7b4fef816d0d3,685bcea8f0904...</td>\n",
       "      <td>4</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>coinbase global, inc.</td>\n",
       "      <td>notes to condensed consolidated financial stat...</td>\n",
       "      <td>26a28882728541699c444e7ab8d1cbfd,4650f0ea382f4...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>net revenue</td>\n",
       "      <td>transaction revenue</td>\n",
       "      <td>6c11c774004842c3892f9cf89ce6868f,6c11c77400484...</td>\n",
       "      <td>4</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>notes to condensed consolidated financial stat...</td>\n",
       "      <td>coinbase global, inc.</td>\n",
       "      <td>26a28882728541699c444e7ab8d1cbfd,4650f0ea382f4...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>statements</td>\n",
       "      <td>beliefs and opinions</td>\n",
       "      <td>685bcea8f090463682d7b4fef816d0d3,685bcea8f0904...</td>\n",
       "      <td>4</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>transaction revenue</td>\n",
       "      <td>net revenue</td>\n",
       "      <td>6c11c774004842c3892f9cf89ce6868f,6c11c77400484...</td>\n",
       "      <td>4</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               node_1  \\\n",
       "3                                beliefs and opinions   \n",
       "12                              coinbase global, inc.   \n",
       "34                                        net revenue   \n",
       "37  notes to condensed consolidated financial stat...   \n",
       "44                                         statements   \n",
       "48                                transaction revenue   \n",
       "\n",
       "                                               node_2  \\\n",
       "3                                          statements   \n",
       "12  notes to condensed consolidated financial stat...   \n",
       "34                                transaction revenue   \n",
       "37                              coinbase global, inc.   \n",
       "44                               beliefs and opinions   \n",
       "48                                        net revenue   \n",
       "\n",
       "                                             chunk_id  count  \\\n",
       "3   685bcea8f090463682d7b4fef816d0d3,685bcea8f0904...      4   \n",
       "12  26a28882728541699c444e7ab8d1cbfd,4650f0ea382f4...      2   \n",
       "34  6c11c774004842c3892f9cf89ce6868f,6c11c77400484...      4   \n",
       "37  26a28882728541699c444e7ab8d1cbfd,4650f0ea382f4...      2   \n",
       "44  685bcea8f090463682d7b4fef816d0d3,685bcea8f0904...      4   \n",
       "48  6c11c774004842c3892f9cf89ce6868f,6c11c77400484...      4   \n",
       "\n",
       "                    edge  \n",
       "3   contextual proximity  \n",
       "12  contextual proximity  \n",
       "34  contextual proximity  \n",
       "37  contextual proximity  \n",
       "44  contextual proximity  \n",
       "48  contextual proximity  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## Melt the dataframe into a list of nodes\n",
    "    dfg_long = pd.melt(\n",
    "        df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "    )\n",
    "    dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "    # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "    dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "    # drop self loops\n",
    "    self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "    dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "    ## Group and count edges.\n",
    "    dfg2 = (\n",
    "        dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "    dfg2.replace(\"\", np.nan, inplace=True)\n",
    "    dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "    dfg2[\"edge\"] = \"contextual proximity\"\n",
    "    return dfg2\n",
    "\n",
    "def dropSingleEdges(dfg2: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop edges with 1 count\n",
    "    dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "    # this is where there is an issue\n",
    "    return dfg2\n",
    "\n",
    "dfg2 = contextual_proximity(dfg1)\n",
    "dfg2 = dropSingleEdges(dfg2)\n",
    "\n",
    "dfg2\n",
    "\n",
    "dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "dfg = (\n",
    "    dfg.groupby([\"node_1\", \"node_2\"])\n",
    "    .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "dfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the NetworkX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "## Add nodes to the graph\n",
    "for node in nodes:\n",
    "    G.add_node(\n",
    "        str(node)\n",
    "    )\n",
    "\n",
    "## Add edges to the graph\n",
    "for index, row in dfg.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"node_1\"]),\n",
    "        str(row[\"node_2\"]),\n",
    "        title=row[\"edge\"],\n",
    "        weight=row['count']/4\n",
    "    )\n",
    "\n",
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "\n",
    "import seaborn as sns\n",
    "palette = \"hls\"\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)\n",
    "\n",
    "for index, row in colors.iterrows():\n",
    "    G.nodes[row['node']]['group'] = row['group']\n",
    "    G.nodes[row['node']]['color'] = row['color']\n",
    "    G.nodes[row['node']]['size'] = G.degree[row['node']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      3\u001b[0m graph_output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./docs/index.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m net \u001b[38;5;241m=\u001b[39m Network(\n\u001b[1;32m      6\u001b[0m     notebook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# bgcolor=\"#1a1a1a\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     filter_menu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m net\u001b[38;5;241m.\u001b[39mfrom_nx(\u001b[43mG\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# net.repulsion(node_distance=150, spring_length=400)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m net\u001b[38;5;241m.\u001b[39mforce_atlas_2based(central_gravity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.015\u001b[39m, gravity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m31\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "graph_output_directory = \"/workspaces/knowledge_graph/docs/index.html\"\n",
    "\n",
    "net = Network(\n",
    "    notebook=False,\n",
    "    # bgcolor=\"#1a1a1a\",\n",
    "    cdn_resources=\"remote\",\n",
    "    height=\"900px\",\n",
    "    width=\"100%\",\n",
    "    select_menu=True,\n",
    "    # font_color=\"#cccccc\",\n",
    "    filter_menu=False,\n",
    ")\n",
    "\n",
    "net.from_nx(G)\n",
    "#the next line may be commented out\n",
    "net.repulsion(node_distance=150, spring_length=400)\n",
    "net.force_atlas_2based(central_gravity=0.015, gravity=-31)\n",
    "#the next line may be commented out\n",
    "net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "net.show_buttons(filter_=[\"physics\"])\n",
    "\n",
    "net.show(graph_output_directory, notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
